{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_multi_variable_linear_regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y2o2u2n/boostcourse-dl-tensorflow/blob/master/04_multi_variable_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7HGw0Fc8YlrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e2ff5cd-f515-4d43-884f-d1feada12fc2"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "3Cqwn1h-ZNh6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# data and label\n",
        "x1 = [ 73., 93., 89., 96., 73.]\n",
        "x2 = [ 80., 88., 91., 98., 66.]\n",
        "x3 = [ 75., 93., 90., 100., 70.]\n",
        "Y = [152., 185., 180., 196., 142.]\n",
        "\n",
        "# random weights\n",
        "w1 = tf.Variable(tf.random_normal([1]))\n",
        "w2 = tf.Variable(tf.random_normal([1]))\n",
        "w3 = tf.Variable(tf.random_normal([1]))\n",
        "b = tf.Variable(tf.random_normal([1]))\n",
        "\n",
        "learning_rate = 0.000001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VslwAM7eZg2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "e04f3c06-16fd-476b-fd53-3584bc6dd47e"
      },
      "cell_type": "code",
      "source": [
        "for i in range(1000+1):\n",
        "  # tf.GradientTape() to record the gradient of the cost function\n",
        "  with tf.GradientTape() as tape:\n",
        "    hypothesis = w1 * x1 + w2 * x2 + w3 * x3 + b\n",
        "    cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "    \n",
        "  # calculates the gradients of the cost\n",
        "  w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b])\n",
        "  \n",
        "  # update w1,w2,w3 and b\n",
        "  w1.assign_sub(learning_rate * w1_grad)\n",
        "  w2.assign_sub(learning_rate * w2_grad)\n",
        "  w3.assign_sub(learning_rate * w3_grad)\n",
        "  b.assign_sub(learning_rate * b_grad)\n",
        "  \n",
        "  if i % 50 == 0:\n",
        "    print(\"{:5} | {:12.4f}\".format(i, cost.numpy()))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 |   28334.4102\n",
            "   50 |     373.7506\n",
            "  100 |      63.3387\n",
            "  150 |      59.7347\n",
            "  200 |      59.5354\n",
            "  250 |      59.3742\n",
            "  300 |      59.2141\n",
            "  350 |      59.0543\n",
            "  400 |      58.8948\n",
            "  450 |      58.7360\n",
            "  500 |      58.5776\n",
            "  550 |      58.4197\n",
            "  600 |      58.2620\n",
            "  650 |      58.1049\n",
            "  700 |      57.9483\n",
            "  750 |      57.7920\n",
            "  800 |      57.6361\n",
            "  850 |      57.4806\n",
            "  900 |      57.3256\n",
            "  950 |      57.1712\n",
            " 1000 |      57.0168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FGv8LggLaPdd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = np.array([\n",
        "  # X1, X2, X3, y\n",
        "  [ 73., 80., 75., 152. ],\n",
        "  [ 93., 88., 93., 185. ],\n",
        "  [ 89., 91., 90., 180. ],\n",
        "  [ 96., 98., 100., 196. ],\n",
        "  [ 73., 66., 70., 142. ]\n",
        "], dtype=np.float32)\n",
        "\n",
        "# slice data\n",
        "X = data[:, :-1]\n",
        "y = data[:, [-1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GBUxpRGUa9fM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W = tf.Variable(tf.random_normal([3, 1]))\n",
        "b = tf.Variable(tf.random_normal([1]))\n",
        "\n",
        "learning_rate = 0.000001\n",
        "\n",
        "# hypothesis, prediction function\n",
        "def predict(X):\n",
        "  return tf.matmul(X, W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JRso5HdGaTx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "f5c4a4df-94c7-4b5e-c51d-6aada3c9d569"
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 2000\n",
        "for i in range(n_epochs + 1):\n",
        "  # record the gradient of the cost function\n",
        "  with tf.GradientTape() as tape:\n",
        "    cost = tf.reduce_mean((tf.square(predict(X) - y)))\n",
        "    \n",
        "  # calculates the gradients of the loss\n",
        "  W_grad, b_grad = tape.gradient(cost, [W, b])\n",
        "  \n",
        "  # updates parameters (W and b)\n",
        "  W.assign_sub(learning_rate * W_grad)\n",
        "  b.assign_sub(learning_rate * b_grad)\n",
        "  \n",
        "  if i % 100 == 0:    \n",
        "    print(\"{:5} | {:10.4f}\".format(i, cost.numpy()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 |    73.9409\n",
            "  100 |    24.5316\n",
            "  200 |    24.4143\n",
            "  300 |    24.3036\n",
            "  400 |    24.1935\n",
            "  500 |    24.0840\n",
            "  600 |    23.9751\n",
            "  700 |    23.8667\n",
            "  800 |    23.7589\n",
            "  900 |    23.6517\n",
            " 1000 |    23.5451\n",
            " 1100 |    23.4391\n",
            " 1200 |    23.3336\n",
            " 1300 |    23.2287\n",
            " 1400 |    23.1243\n",
            " 1500 |    23.0205\n",
            " 1600 |    22.9173\n",
            " 1700 |    22.8145\n",
            " 1800 |    22.7123\n",
            " 1900 |    22.6107\n",
            " 2000 |    22.5096\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}